{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b44d77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Experiments for Yelp Reviews Sentiment Analysis\n",
    "\n",
    "import sys\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9f5f21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the project root to path for imports\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import project modules\n",
    "from src.config import NUM_CLASSES, RANDOM_SEED\n",
    "from src.data.data_loader import YelpDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5135813f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abd35bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-12 01:19:59,696 - src.data.data_loader - INFO - Loading processed data from local files...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed data...\n",
      "Train set shape: (650000, 5)\n",
      "Test set shape: (50000, 3)\n",
      "\n",
      "Sentiment distribution in train set:\n",
      "sentiment\n",
      "0    260000\n",
      "1    130000\n",
      "2    260000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sentiment distribution in test set:\n",
      "sentiment\n",
      "0    20000\n",
      "1    10000\n",
      "2    20000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample reviews and their sentiments:\n",
      "\n",
      "Sentiment: 0\n",
      "Review text: Awful service, awful food.\\n\\nWas here several weeks ago as part of a large group; I arrived partway through the meal and did not order anything, so can't speak for the food on that occasion (though i...\n",
      "\n",
      "Sentiment: 1\n",
      "Review text: Came here after a show and waiting time was 45 mins to an hour.  Promised our son that we would eat here so we waited.  \\n\\nI do not care much for the fire decor they have going in the entrance.  Just...\n",
      "\n",
      "Sentiment: 2\n",
      "Review text: It finally opened! The sign has been on the building for at least 3 seasons, maybe more, but the wait was worth it. We needed a breakfast spot in this central area sorely. The order system is like Pei...\n"
     ]
    }
   ],
   "source": [
    "# 1. Load and Explore the Dataset\n",
    "\n",
    "## 1.1 Load preprocessed data\n",
    "print(\"Loading processed data...\")\n",
    "data_loader = YelpDataLoader()\n",
    "train_df, test_df = data_loader.load_processed_data()\n",
    "\n",
    "print(f\"Train set shape: {train_df.shape}\")\n",
    "print(f\"Test set shape: {test_df.shape}\")\n",
    "\n",
    "# Show distribution of sentiment labels\n",
    "print(\"\\nSentiment distribution in train set:\")\n",
    "print(train_df['sentiment'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nSentiment distribution in test set:\")\n",
    "print(test_df['sentiment'].value_counts().sort_index())\n",
    "\n",
    "# Examine some examples\n",
    "print(\"\\nSample reviews and their sentiments:\")\n",
    "for sentiment in range(NUM_CLASSES):\n",
    "    sample = train_df[train_df['sentiment'] == sentiment].sample(1).iloc[0]\n",
    "    print(f\"\\nSentiment: {sentiment}\")\n",
    "    print(f\"Review text: {sample['text'][:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff0e7003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-12 01:20:02,278 - src.data.dataset - INFO - Created data split: 585000 train, 65000 val, 50000 test\n",
      "2025-04-12 01:20:45,492 - src.data.preprocessor - INFO - Building vocabulary...\n",
      "2025-04-12 01:20:46,264 - src.data.preprocessor - INFO - Vocabulary built with 49999 words\n",
      "2025-04-12 01:20:46,270 - src.data.dataset - INFO - Fitted preprocessor on 100000 samples with vocab size 49999\n",
      "2025-04-12 01:20:46,271 - src.data.dataset - INFO - Created lazy-loading dataset with 585000 samples\n",
      "2025-04-12 01:20:46,271 - src.data.dataset - INFO - Created lazy-loading dataset with 65000 samples\n",
      "2025-04-12 01:20:46,272 - src.data.dataset - INFO - Created lazy-loading dataset with 50000 samples\n",
      "2025-04-12 01:20:46,272 - src.data.dataset - INFO - Created DataLoaders with batch size 64 and 4 workers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch text tensor shape: torch.Size([64, 512])  # [batch_size, max_seq_length]\n",
      "Batch lengths tensor shape: torch.Size([64])  # [batch_size]\n",
      "Batch labels shape: torch.Size([64])  # [batch_size]\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "from src.config import LSTM_CONFIG, VALIDATION_SPLIT\n",
    "from src.data.dataset import create_data_loaders\n",
    "\n",
    "loaders = create_data_loaders(\n",
    "        train_df,\n",
    "        test_df,\n",
    "        VALIDATION_SPLIT,\n",
    "        \"lstm\",\n",
    "        # max_seq_length=max_seq_length,\n",
    "        # max_vocab_size=max_vocab_size,\n",
    "        batch_size=LSTM_CONFIG[\"batch_size\"],\n",
    "        # num_workers=args.num_workers,\n",
    "    )\n",
    "\n",
    "\n",
    "# Check a batch\n",
    "batch = next(iter(loaders[\"train\"]))\n",
    "print(f\"Batch text tensor shape: {batch['text'].shape}  # [batch_size, max_seq_length]\")\n",
    "print(f\"Batch lengths tensor shape: {batch['lengths'].shape}  # [batch_size]\")\n",
    "print(f\"Batch labels shape: {batch['labels'].shape}  # [batch_size]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fe5eb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 50000\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = loaders[\"train\"]\n",
    "val_dataloader = loaders[\"val\"]\n",
    "test_dataloader = loaders[\"test\"]\n",
    "vocab = loaders.get(\"vocab\")  # Get vocabulary for model initialization\n",
    "\n",
    "# Get vocabulary size\n",
    "vocab_size = LSTM_CONFIG[\"max_vocab_size\"]\n",
    "print(f\"Vocabulary size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e078c121",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-12 01:20:46,860 - src.models.lstm_model - INFO - Initialized LSTM model with vocab_size=50000, embedding_dim=300, hidden_dim=256, num_layers=2, dropout=0.3, bidirectional=True, num_classes=3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing LSTM model...\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "from src.models.lstm_model import LSTMSentimentModel\n",
    "\n",
    "\n",
    "print(\"Initializing LSTM model...\")\n",
    "model = LSTMSentimentModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=LSTM_CONFIG[\"embedding_dim\"],\n",
    "    hidden_dim=LSTM_CONFIG[\"hidden_dim\"],\n",
    "    num_layers=LSTM_CONFIG[\"num_layers\"],\n",
    "    bidirectional=LSTM_CONFIG[\"bidirectional\"],\n",
    "    num_classes=NUM_CLASSES,\n",
    "    dropout=LSTM_CONFIG[\"dropout\"],\n",
    "    # padding_idx=vocab.get(\"<PAD>\", 0),\n",
    "    padding_idx=0,\n",
    "    pretrained_embeddings=None,  # TODO: Add support for pretrained embeddings if needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05279976",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-12 01:20:46,877 - src.training.trainer - INFO - Trainer initialized with gradient accumulation over 4 steps\n"
     ]
    }
   ],
   "source": [
    "# Initialize trainer\n",
    "from src.training.trainer import LSTMTrainer\n",
    "\n",
    "trainer = LSTMTrainer(model, device, accumulation_steps=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3075591f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 1 epochs...\n",
      "Avg. time per batch: 0.0853s\n",
      "Estimated time per epoch: 12.99 minutes\n"
     ]
    }
   ],
   "source": [
    "epochs=1\n",
    "# Train model\n",
    "print(f\"Starting training for {epochs} epochs...\")\n",
    "history = trainer.benchmark_training(\n",
    "    model,\n",
    "    train_dataloader,\n",
    "    epochs=epochs\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

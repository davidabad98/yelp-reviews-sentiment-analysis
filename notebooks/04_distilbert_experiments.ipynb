{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b44d77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DistilBERT Experiments for Yelp Reviews Sentiment Analysis\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from transformers import DistilBertTokenizer, AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f5f21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 21:48:49,789 - src.data.preprocessor - INFO - Downloading necessary NLTK resources...\n",
      "[nltk_data] Downloading package punkt to /home/david/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/david/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/david/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "2025-04-09 21:48:51.389814: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-09 21:48:51.517988: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Add the project root to path for imports\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import project modules\n",
    "from src.config import DISTILBERT_CONFIG, NUM_CLASSES, RANDOM_SEED, MODELS_DIR\n",
    "from src.data.data_loader import YelpDataLoader\n",
    "from src.data.preprocessor import DistilBERTPreprocessor\n",
    "from src.models.distilbert_model import DistilBERTSentimentModel\n",
    "from src.training.trainer import DistilBERTTrainer\n",
    "# from src.training.metrics import compute_metrics\n",
    "# from src.utils.visualization import plot_training_history, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5135813f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abd35bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 21:48:53,604 - src.data.data_loader - INFO - Loading processed data from local files...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed data...\n",
      "Train set shape: (650000, 5)\n",
      "Test set shape: (50000, 3)\n",
      "\n",
      "Sentiment distribution in train set:\n",
      "sentiment\n",
      "0    260000\n",
      "1    130000\n",
      "2    260000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sentiment distribution in test set:\n",
      "sentiment\n",
      "0    20000\n",
      "1    10000\n",
      "2    20000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample reviews and their sentiments:\n",
      "\n",
      "Sentiment: 0\n",
      "Review text: Awful service, awful food.\\n\\nWas here several weeks ago as part of a large group; I arrived partway through the meal and did not order anything, so can't speak for the food on that occasion (though i...\n",
      "\n",
      "Sentiment: 1\n",
      "Review text: Came here after a show and waiting time was 45 mins to an hour.  Promised our son that we would eat here so we waited.  \\n\\nI do not care much for the fire decor they have going in the entrance.  Just...\n",
      "\n",
      "Sentiment: 2\n",
      "Review text: It finally opened! The sign has been on the building for at least 3 seasons, maybe more, but the wait was worth it. We needed a breakfast spot in this central area sorely. The order system is like Pei...\n"
     ]
    }
   ],
   "source": [
    "# 1. Load and Explore the Dataset\n",
    "\n",
    "## 1.1 Load preprocessed data\n",
    "print(\"Loading processed data...\")\n",
    "data_loader = YelpDataLoader()\n",
    "train_df, test_df = data_loader.load_processed_data()\n",
    "\n",
    "print(f\"Train set shape: {train_df.shape}\")\n",
    "print(f\"Test set shape: {test_df.shape}\")\n",
    "\n",
    "# Show distribution of sentiment labels\n",
    "print(\"\\nSentiment distribution in train set:\")\n",
    "print(train_df['sentiment'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nSentiment distribution in test set:\")\n",
    "print(test_df['sentiment'].value_counts().sort_index())\n",
    "\n",
    "# Examine some examples\n",
    "print(\"\\nSample reviews and their sentiments:\")\n",
    "for sentiment in range(NUM_CLASSES):\n",
    "    sample = train_df[train_df['sentiment'] == sentiment].sample(1).iloc[0]\n",
    "    print(f\"\\nSentiment: {sentiment}\")\n",
    "    print(f\"Review text: {sample['text'][:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff0e7003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing DistilBERT tokenizer: distilbert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 21:48:57,740 - src.data.dataset - INFO - Created data split: 585000 train, 65000 val, 50000 test\n",
      "2025-04-09 21:48:57,741 - src.data.preprocessor - INFO - Initialized DistilBERT preprocessor with distilbert-base-uncased tokenizer\n",
      "2025-04-09 21:48:57,742 - src.data.dataset - INFO - Created DataLoaders with batch size 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input_ids shape: torch.Size([16, 512])\n",
      "Batch attention_mask shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "# 2. Prepare Data for Training\n",
    "\n",
    "# Initialize tokenizer\n",
    "print(\n",
    "    f\"Initializing DistilBERT tokenizer: {DISTILBERT_CONFIG['pretrained_model_name']}\"\n",
    ")\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\n",
    "    DISTILBERT_CONFIG[\"pretrained_model_name\"]\n",
    ")\n",
    "\n",
    "# 2.1 Create datasets\n",
    "from src.data.dataset import create_data_loaders\n",
    "loaders = create_data_loaders(train_df, test_df, 0.1, \"distilbert\", tokenizer=tokenizer)\n",
    "\n",
    "# Check a batch\n",
    "batch = next(iter(loaders[\"train\"]))\n",
    "print(f\"Batch input_ids shape: {batch['input_ids'].shape}\")\n",
    "print(f\"Batch attention_mask shape: {batch['attention_mask'].shape}\")\n",
    "print(f\"Batch labels shape: {batch['labels'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e078c121",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 21:49:01,087 - src.models.distilbert_model - INFO - Initialized DistilBERT model with pretrained_model=distilbert-base-uncased, hidden_size=768, num_classes=3, dropout=0.1\n"
     ]
    }
   ],
   "source": [
    "# 4. Initialize the DistilBERT Model\n",
    "\n",
    "# 4.1 Create the model instance\n",
    "model = DistilBERTSentimentModel(\n",
    "    pretrained_model_name=DISTILBERT_CONFIG['pretrained_model_name'],\n",
    "    num_classes=NUM_CLASSES,\n",
    "    dropout=0.1,\n",
    "    freeze_bert_layers=None  # We'll fine-tune all layers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1817fd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBERTSentimentModel(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x TransformerBlock(\n",
      "          (attention): DistilBertSdpaAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68bfdfbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 66,365,187\n",
      "Trainable parameters: 66,365,187 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "# Count trainable parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,} ({trainable_params/total_params:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "107d2cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Training Setup\n",
    "\n",
    "# 5.1 Define optimizer and scheduler\n",
    "learning_rate = DISTILBERT_CONFIG['learning_rate']\n",
    "weight_decay = 0.01\n",
    "num_epochs = DISTILBERT_CONFIG['epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50aa7d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/miniconda3/envs/tf/lib/python3.9/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize optimizer with weight decay\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': weight_decay\n",
    "    },\n",
    "    {\n",
    "        'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': 0.0\n",
    "    }\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4d958a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total training steps for scheduler\n",
    "total_steps = len(loaders[\"train\"]) * num_epochs\n",
    "warmup_steps = int(0.1 * total_steps)  # 10% of total steps for warmup\n",
    "\n",
    "# Create scheduler with warmup\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2005f0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 Define loss function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95677304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = DistilBERTTrainer(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19a1c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "print(f\"Starting training for {num_epochs} epochs...\")\n",
    "history = trainer.train(\n",
    "    train_dataloader=loaders[\"train\"],\n",
    "    val_dataloader=loaders[\"val\"],\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=num_epochs,\n",
    "    output_dir=MODELS_DIR,\n",
    "    model_name=\"distilbert\",\n",
    "    # early_stopping_patience=args.early_stopping,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b44d77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DistilBERT Experiments for Yelp Reviews Sentiment Analysis\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from transformers import DistilBertTokenizer, AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f5f21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the project root to path for imports\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import project modules\n",
    "from src.config import DISTILBERT_CONFIG, NUM_CLASSES, RANDOM_SEED, MODELS_DIR\n",
    "from src.data.data_loader import YelpDataLoader\n",
    "from src.data.preprocessor import DistilBERTPreprocessor\n",
    "from src.models.distilbert_model import DistilBERTSentimentModel\n",
    "from src.training.trainer import DistilBERTTrainer\n",
    "# from src.training.metrics import compute_metrics\n",
    "# from src.utils.visualization import plot_training_history, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5135813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd35bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load and Explore the Dataset\n",
    "\n",
    "## 1.1 Load preprocessed data\n",
    "print(\"Loading processed data...\")\n",
    "data_loader = YelpDataLoader()\n",
    "train_df, test_df = data_loader.load_processed_data()\n",
    "\n",
    "print(f\"Train set shape: {train_df.shape}\")\n",
    "print(f\"Test set shape: {test_df.shape}\")\n",
    "\n",
    "# Show distribution of sentiment labels\n",
    "print(\"\\nSentiment distribution in train set:\")\n",
    "print(train_df['sentiment'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nSentiment distribution in test set:\")\n",
    "print(test_df['sentiment'].value_counts().sort_index())\n",
    "\n",
    "# Examine some examples\n",
    "print(\"\\nSample reviews and their sentiments:\")\n",
    "for sentiment in range(NUM_CLASSES):\n",
    "    sample = train_df[train_df['sentiment'] == sentiment].sample(1).iloc[0]\n",
    "    print(f\"\\nSentiment: {sentiment}\")\n",
    "    print(f\"Review text: {sample['text'][:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0e7003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Prepare Data for Training\n",
    "\n",
    "# Initialize tokenizer\n",
    "print(\n",
    "    f\"Initializing DistilBERT tokenizer: {DISTILBERT_CONFIG['pretrained_model_name']}\"\n",
    ")\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\n",
    "    DISTILBERT_CONFIG[\"pretrained_model_name\"]\n",
    ")\n",
    "\n",
    "# 2.1 Create datasets\n",
    "from src.data.dataset import create_data_loaders\n",
    "loaders = create_data_loaders(train_df, test_df, 0.1, \"distilbert\", tokenizer=tokenizer)\n",
    "\n",
    "# Check a batch\n",
    "batch = next(iter(loaders[\"train\"]))\n",
    "print(f\"Batch input_ids shape: {batch['input_ids'].shape}\")\n",
    "print(f\"Batch attention_mask shape: {batch['attention_mask'].shape}\")\n",
    "print(f\"Batch labels shape: {batch['labels'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50469cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = loaders[\"train\"]\n",
    "val_dataloader = loaders[\"val\"]\n",
    "test_dataloader = loaders[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e078c121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Initialize the DistilBERT Model\n",
    "\n",
    "# 4.1 Create the model instance\n",
    "model = DistilBERTSentimentModel(\n",
    "    pretrained_model_name=DISTILBERT_CONFIG['pretrained_model_name'],\n",
    "    num_classes=NUM_CLASSES,\n",
    "    dropout=0.1,\n",
    "    freeze_bert_layers=None  # We'll fine-tune all layers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1817fd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bfdfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count trainable parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,} ({trainable_params/total_params:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107d2cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Training Setup\n",
    "\n",
    "# 5.1 Define optimizer and scheduler\n",
    "learning_rate = DISTILBERT_CONFIG['learning_rate']\n",
    "weight_decay = 0.01\n",
    "num_epochs = DISTILBERT_CONFIG['epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aa7d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize optimizer with weight decay\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': weight_decay\n",
    "    },\n",
    "    {\n",
    "        'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': 0.0\n",
    "    }\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2005f0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 Define loss function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95677304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = DistilBERTTrainer(model, device, accumulation_steps=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19a1c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "print(f\"Starting training for {num_epochs} epochs...\")\n",
    "history = trainer.benchmark_training(\n",
    "    train_dataloader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
